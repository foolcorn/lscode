### 连接池

对数据库进行连接，单个连接处理所有业务，可能业务A阻塞在io上，B会因为A的io阻塞而阻塞，事实上两者完全可以并行，只要不是同时写入，一个读一个写，或者两个读都可以



池化技术将连接用容器管理

新建连接

请求连接

归还连接



一般情况下线程数量和连接数量保持一致



### 线程池



有几种设计模式

- recv，parser，send三个步骤都放到主线程里执行，适合在内存就能完成的业务，不涉及对硬盘的读写（日志）
- 如果parser比较复杂，可以把recv放在主线程，然后把parser，send放到线程里执行
- recv，parser，send三个步骤都放到线程里执行，速度最快，但是有个致命问题是，多个线程共用一个fd，假设发起的请求间隔时间短，socket同时被两个线程在处理



组成

- 任务队列
- 执行队列
- 管理组件：
  - 互斥锁
  - 条件变量

任务队列类{callback，data，next，prev} 

执行队列{线程id，canused优雅指示当前线程是否可用，next，prev}

管理类（线程池）{mutex cond，任务队列，执行队列}

泛型添加节点

泛型删除节点



api

创建线程池（）

pushtask，给线程池添加任务

销毁线程池



性能分析思路：加入线程池比不加线程池效率提升6倍



后期优化点：

- 怎么解决多个线程共用一个fd：协程
- 增加一个job_count计算任务队列数量：根据任务队列和执行队列的比例，动态调整线程池的线程数量，保持一个40%~60%的使用量



### 内存池

如果业务对于客户端的每个请求，都需要使用malloc，一旦频繁使用malloc分配小内存，就容易导致内存碎片

对于小内存，就可以使用内存池的方式进行缓冲



组件：

小内存块（4k）（包含很多碎片）：  

- last：当前分配的碎片结尾

- end：内存最后一个碎片结尾
- next：指向下一个内存块



大内存块（大于4k）：

- next：指向下一个大内存块
- ptr：指向大内存



内存池：

- 大块头指针 head
- 小块头指针 large = null
- 小块当前指针current



有个点比较拗口，就是说内存池的数据结构本身也用内存池来存储(原汤化原食)

api：

创建内存池pool：create(size)

new(p) sizeof pool+size//-这样相当于分配size的前面有一个pool结构体

current = head = p+1





销毁内存池



分配 p = alloc(pool, size)





释放free(pool,p)



接触陌生的服务进程，用htop发现虚拟内存在涨，怎么解决

- 判断内存池是否有内存泄漏：使用内存池在分配和销毁的时候加上打印信息来排错
- 第三方的内存库，是否会有内存泄漏：在哪个业务场景里出现，慢慢排除



 

### 请求池

 

















