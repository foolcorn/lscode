并发量：同时承载的客户端的数量。

承载的意义，并不是建立的连接数量，而是能让这么多数量的客户端的同时请求在200ms内正常返回数据

优化因素：

- 数据库
- 网络带宽
- 内存操作
- 日志



原生epoll能建立多少连接，2w7左右，取决于socketfd的数量

如果服务端的服务器进程只运行在一个端口（目的端口）上（listenfd只有一个），socketfd的数量（一台客户端发起的连接）取决于五元组中源端口数量，

因为内核的range_from可能限定了给网络连接的fd数量就是这么多。

可以通过ulimit -n 修改最大打开文件描述符数量（操作系统重启或者换个进程就不行了）

或者可以改变/etc/security/limits.conf，加入这两个选项

![image-20220622164815065](C:\Users\37412\AppData\Roaming\Typora\typora-user-images\image-20220622164815065.png)

硬限制：不能超界

软限制：超界回收

这样openfile的上限就是100w了



connection timeout的原因

首先有个netfilter的东西可以拦截数据包，比如网卡传送sk_buff到协议栈之前，可以被netfilter给拦截，iptable也是基于netfilter实现的

而timeout的原因很可能是netfilter拦截了服务器回复的ack，导致三次握手失败

可以调参数/etc/sysctl.conf中的net.nf_conntrack_max(设置netfilter 连接的最大数量)

设置完后原生epoll也可以支持百万并发量了，就是因为单线程accept，所以跑的慢



其他还有一些常用配置

net.ipv4.tcp_mem = 262144 524288 786432 （1G，2G， 3G）单位是页page（4K），大于2G优化，大于3G停止

net.ipv4.tcp_wmem = 2048 2048 4096  （默认， 优化， 最大）调节send buffer大小

net.ipv4.tcp_rmem = 2048 2048 4096 （默认，优化，最大）调节recv buffer

如果是大文件传输服务器，就会把这两个值调大

把这两个值调小，则读写占用的内存就小，可以缓解因为内存资源而限制的最大连接数

fs,file_max = 1048576  fd的最大值，这个和数量不一样，因为fd是个int，这个相当于限制了fd的最大值是多少



怎么解决抖动模型（主要原因是只有一个线程在accept，所以处理不过来，全连接队列，半连接队列满了，所以需要在外面排队）

解决方案，开多个线程来accept

常见服务器设计原则;

accept和recv/send分开。

多线程做接入。





reactor在数据拷贝阶段也要求使用非阻塞io



单reactor：类似原生epoll模型，io和业务处理都在一个线程里完成。redis，数据库处理业务快，redis6.0开始多线程（负责处理数据压缩和解压）



redis对epollevent进行了一层封装，针对于不同的活跃事件（事件驱动）

EPOLLIN：封装成可读

EPOLLOUT：封装成可写

EPOLLERR：封装成可读可写

EPOLLHUP写通道和读通道都关闭的时的状态：封装成可读可写

封装成可读可写是为了让用户自己通过read和write的返回值或者应用层的数据，自己处理异常状态

 

accept的时候除了要处理客户端的socketfd，也就是客户端连接，还有可能服务器自己也要和上游服务器进行连接，比如redis，mongo等。

流程：

- 需要调用非阻塞io，调用connect返回-1，同时errno=EINPROGRESS
- 该epollevent关注可写事件
- 向epoll树里加入该event
- eppllout被触发，连接建立成功。（收到第二次握手的ack包）



客户端发送fin包后，写通道关闭    第一次挥手

服务端收到fin包后，读通道关闭   第二次挥手前，然后发送ack

此时服务端可能还要给客户端发送一些数据，发送完数据后也发送fin， 写通道关闭。（第三次挥手）

客户端收到fin后，读通道关闭，然后发送第四次挥手的消息ack，在epoll里就是epollhup 报文



read的返回值

- =0：收到fin包
- \>0:处理正常业务逻辑
- =-1：
  - errno = EWOULDBLOCK recvbuffer无数据
  - errno=EINTER  系统调用被中断
  - errno = ETIMEOUT tcp保活探测包超时



 为什么tcp有保活机制，还需要应用层的心跳检测呢？

传输层的保活机制，不能判断是什么原因引起的，进程阻塞？或者死锁？

应用：

- 数据库间的主从复制，使用心跳
- 客户端与服务器
- 客户端-->反向代理-->上游服务器；反向代理与上游服务器使用tcp保活
- 客户端-->数据库，使用tcp保活，对于数据库而言，不关心客户端是否阻塞



正向代理：client不能直接访问到某个指定的server，但是可以通过nginx作为中间代理连接到该server

反向代理：client不明确指定某个server，而是通过代理分配一个最合适的server来服务





write的返回值

- \>0:   正常，处理业务逻辑
- = -1： 
  - errno = EWOULDBLOCK:
    - send buffer满了
    - 修改epollevent，关注epollout
    - 等后续循环触发epollout
  - errno = EINTR：被中断，后续循环重试
  - errno = EPIPE：写通道关闭





单reactor+任务队列+线程池   ：skynet



多reactor多线程：memcached ： one event per thread

一个accept线程接受连接，多个reactor线程，通过负载均衡分配到不同的reactor上

多reactor多进程：nginx，

多个acceptor，加锁，谁拿到锁就可以接受连接，因为多个accept可以解决抖动。



看redis和nginx源码



### 改造可靠udp

尽力可靠：尽量完整到达：音视频通话

无序可靠：需要完整性，但是可以无序，迅雷下载，整个文件做了分片

有序可靠：完整性+有序



udp

音视频通话

直播是用udp还是tcp，如果使用cdn分发，用的是tcp

直播有延迟，因为接收端会缓存udp，为了解决传输乱序的问题。



游戏开发，棋牌游戏没必要用udp

王者荣耀即时动作游戏，则需要用udp



物联网：

桥梁检查传感器，使用电池，十秒检测一次桥梁状态然后上报，接着休眠，udp更快更方便



服务器状态集中检测：

不需要用tcp保持长连接，



总结：

- 实时性要求
- 节约资源，省电
- 能用tcp的场景，尽量不要用udp



可靠性udp怎么开发

应答机制：用户层自定义

包序号：用户层设计协议

拥塞控制：用户层定义窗口

sendto接口不可以发送大块数据（>MTU），必须分包,udp报文大小最大1472 = 1500-20（IP头至少）-8（udp头），实际一般都<1471

运营商还会加pppoe协议头部，数据包容易越界，所以上限设成1400比较合理

 sendto的时候发送1400字节，recvfrom的时候，必须收完1400，不然剩余的数据就丢失了，因为udp是package传输，而非tcp流式传输



协议设计

同步字

分片数据总大小

分片数量

分片序号

该分片数据大小

保留 



ngtcp2



三次握手发生在协议栈里

客户端应用层调用connect后开始三次握手

客户端协议栈发送syn包（第一次）

服务端收到第一次握手的syn包，把客户端信息加入到syn队列，发送syn+ack包（第二次）

客户端协议栈收到第二次握手包，客户端应用层connect返回，协议栈发送ack包（第三次）

服务端协议栈收到ack包后，把syn队列中的clientfd（怎么辨认，把ack和fd通过五元组联系）改变状态（状态机机制，存在节点（tcp控制块tcb）里）放入全连    接队列，服务端应用层的accept返回就需要从全连接队列拿fd，否则就会阻塞accept



超时重传缺点：确认时间长，重发次数多，因为一旦重传，后续的所有包也会重传

 

大量timewait tcp tw reuse

大量close_wait:  close的正确时机，是否需要把客户端未处理完的剩余业务进行异步处理

大量fin wait 1：无法处理，只能强行kill

大量fin wait 2：无法处理，只能强行kill



